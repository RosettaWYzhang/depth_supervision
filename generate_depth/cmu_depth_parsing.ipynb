{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "# For camera projection (with distortion)\n",
    "import panutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "data_path = ''#'/home/wanyue/Desktop/panoptic-toolbox/'\n",
    "data_path_real = '../'\n",
    "seq_name = '171204_pose3'\n",
    "kinect_img_path = data_path + seq_name + '/kinoptic_rgb/'\n",
    "depth_img_path = data_path + seq_name + '/kinoptic_depth/'\n",
    "confidence_img_path = data_path + seq_name + '/kinoptic_confidence/'\n",
    "bbox_path = data_path_real + seq_name + '/bbox/'\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, 10)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load camera calibration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load camera calibration parameters\n",
    "with open( data_path_real + seq_name + '/kcalibration_{0}.json'.format(seq_name)) as cfile:\n",
    "    calib = json.load(cfile)\n",
    "\n",
    "# append camera index as key eg (50, 1)\n",
    "# for kinect camera, panel = 50, node ranges from 1 to 10 \n",
    "# to be consistent with matlab format, camera index starts with 1\n",
    "cameras = {(50,idx+1):cam for idx, cam in enumerate(calib['sensors'])}\n",
    "\n",
    "# Convert data into numpy arrays for convenience\n",
    "# get rgb camera parameters associated with kinect camera \n",
    "for k,cam in cameras.items():    \n",
    "    cam['K'] = np.matrix(cam['K_color'])\n",
    "    cam['distCoef'] = np.array(cam['distCoeffs_color'])\n",
    "    cam['R'] = np.matrix(np.matrix(cam['M_color'])[0:3,0:3])\n",
    "    cam['t'] = np.matrix(cam['M_color'])[0:3,3].reshape((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras_for_json = {}\n",
    "\n",
    "for cam_id in range(1, 11):\n",
    "    cc = cameras[(50,cam_id)]\n",
    "    cameras_for_json['{0:02d}_{1:02d}'.format(50,cam_id)] = {'K': cc['K'].reshape(9).tolist()[0],\n",
    "                                                            'distCoef': cc['distCoef'].tolist(),\n",
    "                                                            'R': cc['R'].reshape(9).tolist()[0],\n",
    "                                                            't': cc['t'].reshape(3).tolist()\n",
    "                                                           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get names of the image files.\n",
    "import glob\n",
    "image_folder_name = data_path_real+seq_name+'/kinoptic_rgb/50_06/'\n",
    "image_names = sorted(glob.glob(image_folder_name + '*.jpg'))\n",
    "num_images = len(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = num_images - 100 # not counting last 100 images since not all camera has the same number of frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling frames and creating annotation and image objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image objects contains   \n",
    " 'id':       \n",
    " 'cam':   \n",
    " 'image_name':   \n",
    " 'depth_name':  \n",
    " 'confidence_name':   \n",
    " \n",
    " \n",
    "### annotation objects contains:  \n",
    "'id':  \n",
    "'bbox': path of bbox for each image obtained from maskrcnn \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50_08/50_08_00000234.npy'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{0:02d}_{1:02d}/{0:02d}_{1:02d}_{2:08d}.npy'.format(50, selected_cameras[i], img_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "annotations = []\n",
    "sample_rate = 1\n",
    "start_index = 200 \n",
    "cnt = 0\n",
    "for idx in range(num_images)[::sample_rate]: \n",
    "    img_idx = start_index + idx\n",
    "    selected_cameras = [1,2,3,4,5,6,7,8,9,10] # all 10 kinect cameras are selected\n",
    "    for i in range(len(selected_cameras)):\n",
    "        # get bbox first since it may not be defined for all frames (person object is absent)\n",
    "        bbox_full_path = bbox_path + '{0:02d}_{1:02d}/{0:02d}_{1:02d}_{2:08d}.npy'.format(50, selected_cameras[i], img_idx)\n",
    "        if not os.path.exists(bbox_full_path):\n",
    "            continue\n",
    "        bbox_array = np.load(bbox_full_path)\n",
    "        annotations.append( { 'id' : cnt,\n",
    "                              'bbox' : bbox_array.tolist(), # make np array json serializable\n",
    "                            })\n",
    "        \n",
    "        image_path = kinect_img_path+'{0:02d}_{1:02d}/{0:02d}_{1:02d}_{2:08d}.jpg'.format(50, selected_cameras[i], img_idx)\n",
    "        images.append( { 'id': cnt,\n",
    "                        'cam': '{0:02d}_{1:02d}'.format(50,selected_cameras[i]),\n",
    "                        'image_name': kinect_img_path + '{0:02d}_{1:02d}/{0:02d}_{1:02d}_{2:08d}.jpg'.format(50, selected_cameras[i], img_idx),\n",
    "                        'depth_name': depth_img_path + '{0:02d}_{1:02d}/{0:02d}_{1:02d}_{2:08d}.jpg'.format(50, selected_cameras[i], img_idx),\n",
    "                        'confidence_name': confidence_img_path + '{0:02d}_{1:02d}/{0:02d}_{1:02d}_{2:08d}.jpg'.format(50, selected_cameras[i], img_idx)\n",
    "            })\n",
    "\n",
    "        cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = { 'cameras':   cameras_for_json,\n",
    "          'annotations': annotations,\n",
    "          'images': images\n",
    "        }\n",
    "\n",
    "with open('cmu_depth_training.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36873"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
